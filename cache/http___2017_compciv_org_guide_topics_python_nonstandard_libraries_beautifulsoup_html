{"success":true,"status":"completed","completed":1,"total":1,"creditsUsed":1,"expiresAt":"2025-03-05T21:00:14.000Z","data":[{"markdown":"*   [Docs](http://2017.compciv.org/index.html)\n     »\n*   [Guide](http://2017.compciv.org/guide.html)\n     »\n*   Beautiful Soup - HTML and XML parsing\n\n* * *\n\nBeautiful Soup - HTML and XML parsing[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#beautiful-soup-html-and-xml-parsing \"Permalink to this headline\")\n\n================================================================================================================================================================================================\n\nHTML is just a text format, and it can be deserialized into Python objects, just like JSON or CSV. HTML is notoriously messy compared to those data formats, which means there are specialized libraries for doing the work of extracting data from HTML which is essentially impossible with regular expressions alone.\n\nObligatory link to infamous StackOverflow question: “RegEx match open tags except XHTML self-contained tags”\n\n[http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags](http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags)\n\nHTML Basics[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#html-basics \"Permalink to this headline\")\n\n----------------------------------------------------------------------------------------------------------------------------------------------\n\nHTML is yet another language, a _markup language_, to be specific.\n\nTo see the difference between HTML and “just text”, make a HTML file that contains this text:\n\nThis is one line.\n\nThis is another line.\n\nThis is a link: http://www.example.com/\n\nCompare that to a HTML file with that text:\n\n<p\\>This is one line.</p\\>\n\n<p\\>This is another line line.</p\\>\n\n<p\\>This is a <a href\\=\"http://www.example.com/\"\\>link</a\\></p\\>\n\n### HTML tags[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#html-tags \"Permalink to this headline\")\n\nThe most prominent feature of HTML are **tags** that are denoted by angle brackets, e.g. The **p** tag is denoted by an opening tag, `<p>` and a closing tag, `</p>`.\n\n<p\\>This is some text inside paragraph tags</p\\>\n\nTags can be nested within each other:\n\n<p\\>\n    Here is <strong\\>bold text</strong\\>\n</p\\>\n\nNot all tags come in pairs. For instance, line breaks are represented with a single `<br>` tag:\n\n<p\\>Hello\n\n<br\\> World</p\\>\n\n### Tag attributes[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#tag-attributes \"Permalink to this headline\")\n\nThe other prominent feature of HTML is how tags can have **attributes**. For example, the tag `<a>` – think of “a” as short for **anchor** – represents what is commonly known as a **hyperlink**:\n\nThis is supposed to be a <a\\>link</a\\>\n\nBut we commonly think of hyperlinks as, well, _linking_ to something. To encode the destination of an anchor tag, we use the `href` **attribute**:\n\nThis is a <a href\\=\"http://www.example.com\"\\>link</a\\>\n\nThe syntax for HTML tag attributes is:\n\n*   The **name** of the attribute, e.g. `href`\n*   Followed by an **equals** sign with no surrounding whitespace\n*   Followed by a quoted value (common convention is double-quotes)\n\nThe attributes are always in the **opening** tag. And a tag can have multiple attributes:\n\nThis is <a href\\=\"http://www.nytimes.com\" target\\=\"\\_blank\"\\>another link</a\\>\n\n### CSS selectors[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#css-selectors \"Permalink to this headline\")\n\nCSS stands for [Cascading Style Sheets](https://www.w3.org/Style/CSS/Overview.en.html)\n. It’s a whole language of its own, but what we’re most concerned about is the convention of using HTML attributes of `id` and `class` as a way to specify a group of elements:\n\n<p id\\=\"a-first-paragraph\"\\>A paragraph</a\\>\n\n<p class\\=\"hello\"\\>A paragraph with class</p\\>\n\n### Additional reading about HTML[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#additional-reading-about-html \"Permalink to this headline\")\n\nHTML could be its own course. My intent is that you know the fundamentals of HTML – basically, that it’s another data-as-text format – without having to be burdened by the details. Here is some recommended reading to give you some additional background:\n\n*   Getting started with HTML: [https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction\\_to\\_HTML/Getting\\_started](https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Getting_started)\n    \n*   HTML text fundamentals: [https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction\\_to\\_HTML/HTML\\_text\\_fundamentals](https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/HTML_text_fundamentals)\n    \n*   The **HTML** section in Chapter 3 of “Interactive Data Visualization for the Web”: [http://chimera.labs.oreilly.com/books/1230000000345/ch03.html](http://chimera.labs.oreilly.com/books/1230000000345/ch03.html)\n    \n\nThe **HTML** section of “Automate the Boring Stuff” chapter on Web Scraping also contains some useful background material:\n\n[https://automatetheboringstuff.com/chapter11/#calibre\\_link-2937](https://automatetheboringstuff.com/chapter11/#calibre_link-2937)\n\nUsing BeautifulSoup[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#using-beautifulsoup \"Permalink to this headline\")\n\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nThe [BeautifulSoup library](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n, which comes with the Anaconda distribution of Python, is a popular library for **parsing** HTML. By “parse”, I mean, to take raw HTML text and deserialize it into Python objects.\n\nThis is the preferred way of importing the BeautifulSoup library:\n\nfrom bs4 import BeautifulSoup\n\nWe typically want to parse HTML pages fetched from the Internet. But since HTML is _just text_, we can practice on plain old strings of HTML. In the snippet below, I use the variable `html` to refer to a simple HTML formatted string.\n\nI use the `BeautifulSoup()` function, which takes 2 arguments:\n\n*   The **string** of HTML to be parsed\n*   The name of the HTML parser to use, as a string. This second argument, you just memorize as being `\"lxml\"` (BeautifulSoup is meant to be a wrapper around different HTML parsers – a technical detail you don’t need to worry about at this point).\n\nI use the variable named `soup` to refer to the object that the `BeautifulSoup()` function returns. I leave it to you to interactively investigate for yourself what the `type` of that object is, and to read up on its documentation:\n\n[https://www.crummy.com/software/BeautifulSoup/bs4/doc/#making-the-soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#making-the-soup)\n\nfrom bs4 import BeautifulSoup\nhtml \\= '<p>Hello</p> <p>world</p>'\nsoup \\= BeautifulSoup(html, 'lxml')\n\nThe `soup` variable contains a `BeautifulSoup` object, which has a bevy of attributes and methods.\n\nOne is `text`, which will basically remove all of the HTML code and produce the readable text from the HTML:\n\n\\>>> soup.text\n'Hello world'\n\n### Deserializing objects from HTML[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#deserializing-objects-from-html \"Permalink to this headline\")\n\nSometimes the plaintext simplification is useful. But generally, we care about the HTML structure, because the markup often denotes things that are meant to be thought of as discrete objects.\n\nIn the simple HTML string as given – `\"<p>Hello</p> <p>world</p>\"` – we have 2 paragraphs. The `BeautifulSoup` object contains a method named `find_all()` which allows us to deserialize that structure as a **list** of tags:\n\n\\>>> things \\= soup.find\\_all('p')\n\\>>> things\n\\[<p>Hello</p>, <p>world</p>\\]\n\nThose square brackets usually denote a Python **list**. Actually, what we have as a return value of the `find_all()` method, is a `bs4.element.ResultSet` object. Think of it as a special kind of list in the world of `bs4`. Each element of that list is also a special object – e.g. [\\`\\`](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#id1)\n<p>Hello</p>\\` – but more than just a standard Python string:\n\n\\>>> type(things)\nbs4.element.ResultSet\n\\>>> len(things)\n2\n\\>>> t \\= things\\[0\\]\n\\>>> type(t)\nbs4.element.Tag\n\\>>> t.name\n'p'\n\\>>> t.text\n'Hello'\n\n### Extracting attributes from HTML with BeautifulSoup[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#extracting-attributes-from-html-with-beautifulsoup \"Permalink to this headline\")\n\nA very common pattern in web-scraping is to download a page full of links and then to extract the URLs that those links point to, and then programmatically download/parse those pages.\n\nTake a look at [http://www.example.com](http://www.example.com/)\n\nIf you’re using a modern browser, you should be able to right-click and **View Source**. Or you could just `curl` the URL and download it as raw text. Either way, this is an excerpt of what you’ll see:\n\n<body\\>\n<div\\>\n    <h1\\>Example Domain</h1\\>\n    <p\\>This domain is established to be used for illustrative examples in documents. You may use this\n    domain in examples without prior coordination or asking for permission.</p\\>\n    <p\\><a href\\=\"http://www.iana.org/domains/example\"\\>More information...</a\\></p\\>\n</div\\>\n</body\\>\n\nThat “More information...” text is a hyperlink that goes to the URL:\n\n[http://www.iana.org/domains/example](http://www.iana.org/domains/example)\n\nHere’s how to extract that URL with BeautifulSoup – first, we have to use the `requests` library to actually download the contents of that URL:\n\n\\>>> from bs4 import BeautifulSoup\n\\>>> import requests\n\\>>> resp \\= requests.get('http://www.example.com')\n\\>>> html \\= resp.text\n\\>>> soup \\= BeautifulSoup(html, 'lxml')\n\nUse the `find_all()` method of the `soup` object to specify the `<a>` tags. Though there’s only one hyperlink in this HTML text, it’s still treated as a list (or rather, a `ResultSet`) of _one element_:\n\n\\>>> tags \\= soup.find\\_all('a')\n\\>>> tags\n\\[<a href=\"http://www.iana.org/domains/example\">More information...</a>\\]\n\\>>> t \\= tags\\[0\\]\n\\>>> t\n<a href=\"http://www.iana.org/domains/example\">More information...</a>\n\\>>> type(t)\nbs4.element.Tag\n\\>>> t.text\n'More information...'\n\nThe `Tag` object also a `attrs` attribute, which returns a **dict** object of the HTML tag’s attributes. In this case, there is only one attribute:\n\n\\>>> type(t.attrs)\ndict\n\\>>> t.attrs\n{'href': 'http://www.iana.org/domains/example'}\n\\>>> t.attrs\\['href'\\]\n'http://www.iana.org/domains/example'\n\nWhat if we want to print all the URLs that are linked to from the page at `http://www.iana.org/domains/example`? See if you can repeat the above logic on your own:\n\n(for explicitness sake, I pretend we’re writing a script from scratch)\n\nfrom bs4 import BeautifulSoup\nimport requests\n\nresp \\= requests.get('http://www.example.com')\nsoup \\= BeautifulSoup(resp.text, 'lxml')\n\nnew\\_url \\= soup.find\\_all('a')\\[0\\]\\['href'\\]\n\nnew\\_resp \\= requests.get(new\\_url)\nnew\\_soup \\= BeautifulSoup(new\\_resp.text, 'lxml')\n\nlinks \\= new\\_soup.find\\_all('a')\n\nfor link in links:\n    print(link.attrs\\['href'\\])\n\n### CSS selectors with BeautifulSoup[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#css-selectors-with-beautifulsoup \"Permalink to this headline\")\n\nNote: I’m kind of new to BS4 myself. `find_all()` is a nice method, but ultimately, I think we want to use the `BeautifulSoup` object’s method of `select()`:\n\nfrom bs4 import BeautifulSoup\nimport requests\n\nresp \\= requests.get('http://www.example.com')\nsoup \\= BeautifulSoup(resp.text, 'lxml')\n\nlinks \\= soup.select('a')\n\nRead more here:\n\n[https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors)\n\n### More reading about BeautifulSoup[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#more-reading-about-beautifulsoup \"Permalink to this headline\")\n\nI don’t recommend reading _all_ of the documentation on BeautifulSoup. But here are some examples/sections that you should familiarize yourself with:\n\n#### Official documentation[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#official-documentation \"Permalink to this headline\")\n\n*   Making the soup: [https://www.crummy.com/software/BeautifulSoup/bs4/doc/#making-the-soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#making-the-soup)\n    \n*   Kinds of objects: [https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kinds-of-objects](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kinds-of-objects)\n    \n*   Navigating the tree: [https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree)\n    \n*   Searching the tree: [https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree)\n    \n*   Calling a tag is like calling `find_all()`: [https://www.crummy.com/software/BeautifulSoup/bs4/doc/#calling-a-tag-is-like-calling-find-all](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#calling-a-tag-is-like-calling-find-all)\n    \n*   CSS selectors: [https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors)\n    \n\nThe “Automate the Boring Stuff” textbook has a [whole chapter on Web Scraping](https://automatetheboringstuff.com/chapter11/)\n. But it encompasses a lot about web-scraping beyond HTML parsing.\n\nFor the purposes of this lesson, read the following sections:\n\n*   Opening Your Browser’s Developer Tools\n*   Using the Developer Tools to Find HTML Elements\n*   Creating a BeautifulSoup Object from HTML\n*   Finding an Element with the select() Method\n*   Getting Data from an Element’s Attributes\n\n### Cats and Dogs exercises[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#cats-and-dogs-exercises \"Permalink to this headline\")\n\nDo you know HTML parsing? Then try this exercise:\n\nGiven the HTML at this URL:\n\n[http://stash.compciv.org/2017/webby/pets.html](http://stash.compciv.org/2017/webby/pets.html)\n\n1.  Print the total number of URLs.\n2.  Print the total number of URLs that are nested in a <li> tag.\n3.  Print the number of links that have a `dog` class.\n4.  Print all the URLs of the links that are of class `cat` and `video`\n5.  Print the text and URL of each hyperlink that has a class of `dog` and `article`\n\n#### Answers[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#answers \"Permalink to this headline\")\n\nDownload the contents of the URL and make it into soup:\n\nfrom bs4 import BeautifulSoup\nimport requests\n\nURL \\= 'http://stash.compciv.org/2017/webby/pets.html'\n\nrawhtml \\= requests.get(URL).text\nsoup \\= BeautifulSoup(rawhtml, 'lxml')\n\n##### 1\\. Print the total number of URLs.[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#print-the-total-number-of-urls \"Permalink to this headline\")\n\n\\>>> links \\= soup.select('a')\n\\>>> print(len(links))\n10\n\n##### 2\\. Print number of URLs that are nested in a <li> tag.[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#print-number-of-urls-that-are-nested-in-a-li-tag \"Permalink to this headline\")\n\n\\>>> links \\= soup.select('li a')\n\\>>> print(len(links))\n8\n\n##### 3\\. Print the number of links that have a `dog` class.[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#print-the-number-of-links-that-have-a-dog-class \"Permalink to this headline\")\n\n\\>>> links \\= soup.select('a.dog')\n\\>>> print(len(links))\n4\n\n##### 4\\. Print the URLs of the links that are of class `cat` and `video`[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#print-the-urls-of-the-links-that-are-of-class-cat-and-video \"Permalink to this headline\")\n\n\\>>> links \\= soup.select('a.cat.video')\n\\>>> for a in links:\n...:    atts = a.attrs\n...:    print(atts\\['href'\\])\nhttps://www.youtube.com/watch?v=2XID\\_W4neJo\nhttps://www.youtube.com/watch?v=tntOCGkgt98\nhttps://www.youtube.com/watch?v=nX1YzS\\_CYIw\nhttps://www.youtube.com/watch?v=pNhESKKiEDI\n\n##### 5\\. Print text and URL of each hyperlink that has class of `dog` and `article`[¶](http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html#print-text-and-url-of-each-hyperlink-that-has-class-of-dog-and-article \"Permalink to this headline\")\n\nfor a in soup.select('a.dog.article'):\n    print(a.text, a.attrs\\['href'\\])\n\nNote how whitespace (i.e. the newline characters) from the original HTML are preserved in the printed values:\n\n                A dog that does not work\n             https://en.wikipedia.org/wiki/Companion\\_dog\nDogs in the military http://ngm.nationalgeographic.com/2014/06/war-dogs/paterniti-text","metadata":{"title":"Beautiful Soup - HTML and XML parsing","language":"en","viewport":"width=device-width, initial-scale=1.0","scrapeId":"31d03261-c592-410c-9639-583bedb39060","sourceURL":"http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html","url":"http://2017.compciv.org/guide/topics/python-nonstandard-libraries/beautifulsoup.html","statusCode":200}}]}