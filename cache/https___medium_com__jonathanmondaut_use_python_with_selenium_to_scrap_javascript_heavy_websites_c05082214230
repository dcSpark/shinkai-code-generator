{"success":true,"status":"completed","completed":1,"total":1,"creditsUsed":1,"expiresAt":"2025-03-05T20:55:48.000Z","data":[{"markdown":"[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc05082214230&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40jonathanmondaut%2Fuse-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[](https://medium.com/?source=---top_nav_layout_nav-----------------------------------------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\n[](https://medium.com/search?source=---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40jonathanmondaut%2Fuse-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\n[Mastodon](https://me.dm/@jonathanmondaut)\n\nUse Python with Selenium to scrap Javascript heavy websites\n===========================================================\n\n[![Jonathan Mondaut](https://miro.medium.com/v2/resize:fill:88:88/1*l5fK8FSzNIoABmkxgZZhHg.png)](https://medium.com/@jonathanmondaut?source=post_page---byline--c05082214230---------------------------------------)\n\n[Jonathan Mondaut](https://medium.com/@jonathanmondaut?source=post_page---byline--c05082214230---------------------------------------)\n\n·\n\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F37e6dd84fbf3&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40jonathanmondaut%2Fuse-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230&user=Jonathan+Mondaut&userId=37e6dd84fbf3&source=post_page-37e6dd84fbf3--byline--c05082214230---------------------post_header------------------)\n\n5 min read\n\n·\n\nJun 17, 2022\n\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc05082214230&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40jonathanmondaut%2Fuse-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230&user=Jonathan+Mondaut&userId=37e6dd84fbf3&source=---header_actions--c05082214230---------------------clap_footer------------------)\n\n\\--\n\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc05082214230&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40jonathanmondaut%2Fuse-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230&source=---header_actions--c05082214230---------------------bookmark_footer------------------)\n\nListen\n\nShare\n\nSelenium is a wonderful tool which allows you to automate website testing by reproducing user’s actions. But well, a lot of people actually use it for other purposes like web scraping.\n\nIn fact, Selenium basically uses browsers’ driver to execute fetched page. Consequently, the program could have access easily to data which are complicated to obtain using traditional scraper or crawler.\n\n_If you are not able to visualise the content until the end, I invite you to take a look_ [_here_](https://jack-of-all-trades.dev/data)\n _to catch-up!_\n\nFinding information by searching on the website\n===============================================\n\nLet’s jump directly into today’s project. We are going to find out what is the list of Dragon Ball’s Son Goku action figures with their price on the website I build for the experiment that I describe [here](https://medium.com/@jonathanmondaut/scrap-data-with-pandas-in-python-8227acb45222)\n.\n\nFirstly, we import the packages up and get some functions ready to output our data. We are going to output our data in a CSV file so it makes the process easier.\n\nfrom selenium import webdriver  \nfrom selenium.webdriver.common.keys import Keys  \nfrom selenium.webdriver.common.by import By  \nfrom selenium.webdriver.support.ui import WebDriverWait  \nfrom selenium.webdriver.support import expected\\_conditions as EC  \nfrom selenium.webdriver.chrome.options import Optionsimport csv  \nimport timedef setCSV(output\\_file, headers):  \n    writer = csv.DictWriter(output\\_file, fieldnames=headers)  \n    writer.writeheader()  \n    return writerdef writeRowsCSV(writer, data):  \n    print(data)  \n    for row in data:  \n        print(\"Write row\")  \n        print(row)  \n        writer.writerow(row)\n\nWe imported a bunch of functionalities from Selenium which have the following uses in our script:\n\n*   **webdriver**: webdriver constructor, in other words to initialize Selenium with a driver\n*   **Options**: helps to set options in the webdriver.\n*   **Keys**: collection of keys of the keyboard.\n*   **By**: collection of method to find elements.\n*   **WebDriverWait**: makes the inputted driver wait explicitly, functions like _“until()”_ can be added to stop waiting when a condition is true.\n*   **expected\\_conditions**: collection of conditions which we can use with the above mentioned _“until()”_ function.\n\nHere is the explained process to get our data. We are just following the process anyone would do to get the information required. In order to do this, I use Google Chrome Dev Tool to inspect the page and take note of which attribute, element or structure I could use to differentiate the element I need to find from others. You can see below a screenshot of me looking for the search bar.\n\n![Process to find an element easily in the DOM](https://miro.medium.com/v2/resize:fit:700/1*NNeg4I7Ibd9OWrLvTp26fg.png)\n\nInspecting Figurines-maniac.com homepage, process\n\nOur plan is to get all action figures of Goku. So, we instinctively would input our keyword in the search bar and press enter. That is exactly what we are going to do. But before we need to initialize Selenium with the driver of the browser we want to use.\n\nchrome\\_options = Options()  \nchrome\\_options.add\\_argument(\"--headless\")  \ndriver = webdriver.Chrome(options=chrome\\_options)\n\nAs a note, I use Chrome driver, so I downloaded separately from Selenium the driver as it is explained in [Selenium’s documentation](https://selenium-python.readthedocs.io/installation.html#drivers)\n for the setup. I also added the _“headless”_ argument because I don’t want to see the browser open up doing the actions I ask for, but instead just doing it in the background.\n\nOnce Selenium is initialized, we get the webpage and input our keyword in the search bar and press _“Enter”_ key. You can notice that I use some _time.sleep()_ functions to explicitly wait a bit in order to make the script more human and let time for the webpage to process the input just in case there is some kind of _“onChange”_ event.\n\ndriver.get(\"[https://www.figurines-maniac.com/](https://www.figurines-maniac.com/)\n\")  \ntime.sleep(2)  \nelem = WebDriverWait(driver, 30).until(  \n   EC.presence\\_of\\_element\\_located((By.XPATH,'//input\\[[@class](http://twitter.com/class)\\\n\\=\"header-search-input\"\\]'))  \n)  \nelem.send\\_keys(\"Goku\")  \ntime.sleep(1)  \nelem.send\\_keys(Keys.RETURN)  \ntime.sleep(4)\n\n![Figurines-maniac.com, Goku search result](https://miro.medium.com/v2/resize:fit:700/1*D-wTOTaVkKLNPjFIGc7UrA.png)\n\nFigurines-maniac.com, Goku search result\n\nNext, we need to look for action figures list in the page. Our eyes are naturally trained for this, but once again our little script need our help to find them. And he doesn’t know what we are looking for, here we are going to indicate it what information we need. I will need three information, the product name, the price and the link to the product as I may be interested to buy it later on.\n\nThe name I chose for those information are pretty straightforward. I named them _“product\\_name”_, _“price”_ and _“url”_.\n\n\\# Looking for the list of products  \nproducts\\_ul = driver.find\\_elements(By.XPATH, '//ul\\[contains([@class](http://twitter.com/class)\\\n, \"products\")\\]')  \nprint(products\\_ul)  \nif len(products\\_ul) > 0:  \n    product\\_list = \\[\\]  \n    # Getting data for every product in the list  \n    for product in products\\_ul\\[0\\].find\\_elements(By.XPATH, './/li'):  \n        product\\_title = product.find\\_elements(By.XPATH, './/h2')  \n        if len(product\\_title) > 0:  \n            product\\_name = product.find\\_element(By.XPATH, './/h2').text if len(product.find\\_elements(By.XPATH, './/h2')) > 0 else \"Product not found\"  \n            price = product.find\\_element(By.XPATH, './/bdi').text if len(product.find\\_elements(By.XPATH, './/bdi')) > 0 else \"Price not found\"  \n            url = product.find\\_elements(By.XPATH, './/a')\\[0\\].get\\_attribute(\"href\") if len(product.find\\_elements(By.XPATH, './/a')) > 0 else \"URL not found\"  \n            product\\_list.append({  \n                \"product\\_name\": product\\_name, # a job-card-list\\_\\_title  \n                \"price\": price, # a job-card-container\\_\\_company-name  \n                \"url\": url  \n            })  \n    print(product\\_list)  \n    # Outputting scrapped data to CSV file  \n    with open(\"products\\_output.csv\",\"w\", encoding=\"utf-8\") as output\\_file:  \n        headers = \\[\"product\\_name\", \"price\", \"url\"\\]  \n        writer = setCSV(output\\_file, headers)  \n        writeRowsCSV(writer, product\\_list)\n\nLet’s not forget the clean it up and close the browser once done.\n\nif driver is not None:  \n    driver.close()\n\nAnd we are done. Selenium is easy to use and is really helpful to collect data from website where you may need to execute complete actions like logging in or searching before getting the data. You can find below the full code for you to enjoy!\n\nIf you enjoyed the article or found it useful, it would be kind of you to support me by following me here ([Jonathan Mondaut](https://medium.com/subscribe/@jonathanmondaut)\n). More articles are coming very soon!\n\nfrom selenium import webdriver  \nfrom selenium.webdriver.common.keys import Keys  \nfrom selenium.webdriver.common.by import By  \nfrom selenium.webdriver.support.ui import WebDriverWait  \nfrom selenium.webdriver.support import expected\\_conditions as EC  \nfrom selenium.webdriver.chrome.options import Optionsimport csv  \nimport timedef setCSV(output\\_file, headers):  \n    writer = csv.DictWriter(output\\_file, fieldnames=headers)  \n    writer.writeheader()  \n    return writerdef writeRowsCSV(writer, data):  \n    print(data)  \n    for row in data:  \n        print(\"Write row\")  \n        print(row)  \n        writer.writerow(row)try:  \n    chrome\\_options = Options()  \n    chrome\\_options.add\\_argument(\"--headless\")  \n    driver = webdriver.Chrome(options=chrome\\_options)  \n    driver.get(\"[https://www.figurines-maniac.com/](https://www.figurines-maniac.com/)\n\")  \n    time.sleep(2)  \n    elem = WebDriverWait(driver, 30).until(  \n                EC.presence\\_of\\_element\\_located((By.XPATH, '//input\\[[@class](http://twitter.com/class)\\\n\\=\"header-search-input\"\\]'))  \n            )  \n    elem.send\\_keys(\"Goku\")  \n    time.sleep(1)  \n    elem.send\\_keys(Keys.RETURN)  \n    time.sleep(4)products\\_ul = driver.find\\_elements(By.XPATH, '//ul\\[contains([@class](http://twitter.com/class)\\\n, \"products\")\\]')  \n    print(products\\_ul)  \n    if len(products\\_ul) > 0:  \n        product\\_list = \\[\\]  \n        for product in products\\_ul\\[0\\].find\\_elements(By.XPATH, './/li'):  \n            product\\_title = product.find\\_elements(By.XPATH, './/h2')  \n            if len(product\\_title) > 0:  \n                product\\_name = product.find\\_element(By.XPATH, './/h2').text if len(product.find\\_elements(By.XPATH, './/h2')) > 0 else \"Product not found\"  \n                price = product.find\\_element(By.XPATH, './/bdi').text if len(product.find\\_elements(By.XPATH, './/bdi')) > 0 else \"Price not found\"  \n                url = product.find\\_elements(By.XPATH, './/a')\\[0\\].get\\_attribute(\"href\") if len(product.find\\_elements(By.XPATH, './/a')) > 0 else \"URL not found\"  \n                product\\_list.append({  \n                    \"product\\_name\": product\\_name, # a job-card-list\\_\\_title  \n                    \"price\": price, # a job-card-container\\_\\_company-name  \n                    \"url\": url  \n                })  \n        print(product\\_list)  \n        with open(\"products\\_output.csv\",\"w\", encoding=\"utf-8\") as output\\_file:  \n            headers = \\[\"product\\_name\", \"price\", \"url\"\\]  \n            writer = setCSV(output\\_file, headers)  \n            writeRowsCSV(writer, product\\_list)  \n    if driver is not None:  \n        driver.close()  \nexcept Exception as error:  \n    print(error)  \n    driver.close()\n\n![](https://miro.medium.com/v2/da:true/resize:fit:0/5c50caa54067fd622d2f0fac18392213bf92f6e2fae89b691e62bceb40885e74)\n\nSign up to discover human stories that deepen your understanding of the world.\n------------------------------------------------------------------------------\n\nFree\n----\n\nDistraction-free reading. No ads.\n\nOrganize your knowledge with lists and highlights.\n\nTell your story. Find your audience.\n\nSign up for free\n\nMembership\n----------\n\nRead member-only stories\n\nSupport writers you read most\n\nEarn money for your writing\n\nListen to audio narrations\n\nRead offline with the Medium app\n\nTry for 5/month\n\n[Python](https://medium.com/tag/python?source=post_page-----c05082214230---------------------------------------)\n\n[Selenium](https://medium.com/tag/selenium?source=post_page-----c05082214230---------------------------------------)\n\n[Scraping](https://medium.com/tag/scraping?source=post_page-----c05082214230---------------------------------------)\n\n[Data Science](https://medium.com/tag/data-science?source=post_page-----c05082214230---------------------------------------)\n\n[Data](https://medium.com/tag/data?source=post_page-----c05082214230---------------------------------------)\n\n[![Jonathan Mondaut](https://miro.medium.com/v2/resize:fill:96:96/1*l5fK8FSzNIoABmkxgZZhHg.png)](https://medium.com/@jonathanmondaut?source=post_page---post_author_info--c05082214230---------------------------------------)\n\n[![Jonathan Mondaut](https://miro.medium.com/v2/resize:fill:128:128/1*l5fK8FSzNIoABmkxgZZhHg.png)](https://medium.com/@jonathanmondaut?source=post_page---post_author_info--c05082214230---------------------------------------)\n\nFollow\n\n[Written by Jonathan Mondaut\\\n---------------------------](https://medium.com/@jonathanmondaut?source=post_page---post_author_info--c05082214230---------------------------------------)\n\n[1.7K Followers](https://medium.com/@jonathanmondaut/followers?source=post_page---post_author_info--c05082214230---------------------------------------)\n\n·[41 Following](https://medium.com/@jonathanmondaut/following?source=post_page---post_author_info--c05082214230---------------------------------------)\n\nEngineering Manager & AI at work Ambassador at Publicis Sapient\n\nFollow\n\nNo responses yet\n----------------\n\n[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--c05082214230---------------------------------------)\n\n![](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)\n\nWrite a response\n\n[What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40jonathanmondaut%2Fuse-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230&source=---post_responses--c05082214230---------------------respond_sidebar------------------)\n\nCancel\n\nRespond\n\nAlso publish to my profile\n\n[Help](https://help.medium.com/hc/en-us?source=post_page-----c05082214230---------------------------------------)\n\n[Status](https://medium.statuspage.io/?source=post_page-----c05082214230---------------------------------------)\n\n[About](https://medium.com/about?autoplay=1&source=post_page-----c05082214230---------------------------------------)\n\n[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----c05082214230---------------------------------------)\n\n[Press](mailto:pressinquiries@medium.com)\n\n[Blog](https://blog.medium.com/?source=post_page-----c05082214230---------------------------------------)\n\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c05082214230---------------------------------------)\n\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c05082214230---------------------------------------)\n\n[Text to speech](https://speechify.com/medium?source=post_page-----c05082214230---------------------------------------)\n\n[Teams](https://medium.com/business?source=post_page-----c05082214230---------------------------------------)","metadata":{"favicon":"https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19","article:author":"https://medium.com/@jonathanmondaut","twitter:app:url:iphone":"medium://p/c05082214230","twitter:description":"Selenium is a wonderful tool which allows you to automate website testing by reproducing user’s actions. But well, a lot of people actually…","twitter:image:alt":"Figurines-maniac.com, Goku search result","ogDescription":"Selenium is a wonderful tool which allows you to automate website testing by reproducing user’s actions. But well, a lot of people actually…","twitter:data1":"5 min read","og:site_name":"Medium","twitter:card":"summary_large_image","og:image":"https://miro.medium.com/v2/resize:fit:1200/1*D-wTOTaVkKLNPjFIGc7UrA.png","author":"Jonathan Mondaut","title":"Use Python with Selenium to scrap Javascript heavy websites | by Jonathan Mondaut | Medium","ogUrl":"https://medium.com/@jonathanmondaut/use-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230","al:ios:app_name":"Medium","description":"Selenium is a wonderful tool which allows you to automate website testing by reproducing user’s actions. But well, a lot of people actually use it for other purposes like web scraping. In fact…","ogSiteName":"Medium","fb:app_id":"542599432471018","og:url":"https://medium.com/@jonathanmondaut/use-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230","twitter:app:name:iphone":"Medium","ogImage":"https://miro.medium.com/v2/resize:fit:1200/1*D-wTOTaVkKLNPjFIGc7UrA.png","twitter:site":"@Medium","al:ios:url":"medium://p/c05082214230","al:android:app_name":"Medium","robots":"index,noarchive,follow,max-image-preview:large","theme-color":"#000000","al:ios:app_store_id":"828256236","al:android:package":"com.medium.reader","og:title":"Use Python with Selenium to scrap Javascript heavy websites","og:image:alt":"Figurines-maniac.com, Goku search result","viewport":"width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1","twitter:title":"Use Python with Selenium to scrap Javascript heavy websites","twitter:image:src":"https://miro.medium.com/v2/resize:fit:1200/1*D-wTOTaVkKLNPjFIGc7UrA.png","twitter:creator":"@JonathanMONDAUT","twitter:label1":"Reading time","twitter:app:id:iphone":"828256236","publishedTime":"2024-11-08T17:18:40.182Z","al:web:url":"https://medium.com/@jonathanmondaut/use-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230","al:android:url":"medium://p/c05082214230","language":"en","ogTitle":"Use Python with Selenium to scrap Javascript heavy websites","og:type":"article","article:published_time":"2024-11-08T17:18:40.182Z","og:description":"Selenium is a wonderful tool which allows you to automate website testing by reproducing user’s actions. But well, a lot of people actually…","referrer":"unsafe-url","scrapeId":"a85ab5c8-59e2-4939-84ef-c470e540b927","sourceURL":"https://medium.com/@jonathanmondaut/use-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230","url":"https://medium.com/@jonathanmondaut/use-python-with-selenium-to-scrap-javascript-heavy-websites-c05082214230","statusCode":200}}]}